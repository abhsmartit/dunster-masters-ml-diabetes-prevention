{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79ebe768",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "## Masters in AI & ML Project\n",
    "\n",
    "This notebook performs comprehensive exploratory data analysis on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec42c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print('âœ“ Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f7111d",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "# Replace 'your_dataset.csv' with your actual file path\n",
    "data_path = '../data/raw/your_dataset.csv'\n",
    "\n",
    "# Uncomment the appropriate line based on your file type\n",
    "# df = pd.read_csv(data_path)\n",
    "# df = pd.read_excel(data_path)\n",
    "\n",
    "# For demonstration, create a sample dataset\n",
    "# Remove this when you have your own data\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=8, \n",
    "                          n_redundant=2, random_state=42)\n",
    "df = pd.DataFrame(X, columns=[f'Feature_{i+1}' for i in range(10)])\n",
    "df['Target'] = y\n",
    "\n",
    "print(f'Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d2052",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a75ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print('\\nðŸ“Š First 5 rows:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b6fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info\n",
    "print('\\nðŸ“‹ Dataset Information:')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print('\\nðŸ“ˆ Statistical Summary:')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206139c1",
   "metadata": {},
   "source": [
    "## 3. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9152fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing.index,\n",
    "    'Missing_Count': missing.values,\n",
    "    'Missing_Percentage': missing_pct.values\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print('\\nâŒ Missing Values:')\n",
    "print(missing_df[missing_df['Missing_Count'] > 0])\n",
    "\n",
    "# Visualize missing values\n",
    "if missing.sum() > 0:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=missing_pct.values, y=missing_pct.index)\n",
    "    plt.xlabel('Percentage of Missing Values')\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('âœ“ No missing values found!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1008eba7",
   "metadata": {},
   "source": [
    "## 4. Data Types and Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7688754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data types and unique values\n",
    "dtype_df = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Data_Type': df.dtypes.values,\n",
    "    'Unique_Values': [df[col].nunique() for col in df.columns],\n",
    "    'Sample_Value': [df[col].iloc[0] for col in df.columns]\n",
    "})\n",
    "\n",
    "print('\\nðŸ”¤ Data Types and Unique Values:')\n",
    "dtype_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebde9a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical and categorical columns\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f'\\nðŸ”¢ Numerical columns ({len(numerical_cols)}): {numerical_cols}')\n",
    "print(f'\\nðŸ“ Categorical columns ({len(categorical_cols)}): {categorical_cols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a64f2",
   "metadata": {},
   "source": [
    "## 5. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e270ab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target variable\n",
    "# Adjust 'Target' to your actual target column name\n",
    "target_col = 'Target'\n",
    "\n",
    "if target_col in df.columns:\n",
    "    print(f'\\nðŸŽ¯ Target Variable: {target_col}')\n",
    "    print('\\nValue Counts:')\n",
    "    print(df[target_col].value_counts())\n",
    "    \n",
    "    print('\\nDistribution:')\n",
    "    print(df[target_col].value_counts(normalize=True) * 100)\n",
    "    \n",
    "    # Visualize target distribution\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Count plot\n",
    "    df[target_col].value_counts().plot(kind='bar', ax=ax1, color='skyblue')\n",
    "    ax1.set_title(f'Target Variable Distribution')\n",
    "    ax1.set_xlabel(target_col)\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Pie chart\n",
    "    df[target_col].value_counts().plot(kind='pie', ax=ax2, autopct='%1.1f%%')\n",
    "    ax2.set_title(f'Target Variable Proportion')\n",
    "    ax2.set_ylabel('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8052d26f",
   "metadata": {},
   "source": [
    "## 6. Numerical Features Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0fb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of numerical features\n",
    "if len(numerical_cols) > 0:\n",
    "    n_cols = 3\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 4))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(numerical_cols):\n",
    "        if idx < len(axes):\n",
    "            df[col].hist(bins=30, ax=axes[idx], edgecolor='black')\n",
    "            axes[idx].set_title(f'Distribution of {col}')\n",
    "            axes[idx].set_xlabel(col)\n",
    "            axes[idx].set_ylabel('Frequency')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(len(numerical_cols), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0b335",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364fc610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "if len(numerical_cols) > 1:\n",
    "    correlation = df[numerical_cols].corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=1)\n",
    "    plt.title('Correlation Matrix', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find highly correlated features\n",
    "    high_corr = []\n",
    "    for i in range(len(correlation.columns)):\n",
    "        for j in range(i+1, len(correlation.columns)):\n",
    "            if abs(correlation.iloc[i, j]) > 0.8:\n",
    "                high_corr.append((correlation.columns[i], \n",
    "                                correlation.columns[j], \n",
    "                                correlation.iloc[i, j]))\n",
    "    \n",
    "    if high_corr:\n",
    "        print('\\nâš ï¸ Highly correlated features (|correlation| > 0.8):')\n",
    "        for feat1, feat2, corr_val in high_corr:\n",
    "            print(f'   {feat1} <-> {feat2}: {corr_val:.3f}')\n",
    "    else:\n",
    "        print('\\nâœ“ No highly correlated features found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1e254",
   "metadata": {},
   "source": [
    "## 8. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da615f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for outlier detection\n",
    "if len(numerical_cols) > 0:\n",
    "    n_cols = 3\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 4))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(numerical_cols):\n",
    "        if idx < len(axes):\n",
    "            df.boxplot(column=col, ax=axes[idx])\n",
    "            axes[idx].set_title(f'Box Plot - {col}')\n",
    "            axes[idx].set_ylabel(col)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(len(numerical_cols), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b06d973",
   "metadata": {},
   "source": [
    "## 9. Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features\n",
    "if len(categorical_cols) > 0:\n",
    "    for col in categorical_cols:\n",
    "        print(f'\\nðŸ“Š {col}:')\n",
    "        print(df[col].value_counts())\n",
    "        \n",
    "        # Plot if reasonable number of categories\n",
    "        if df[col].nunique() <= 20:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            df[col].value_counts().plot(kind='bar', color='coral')\n",
    "            plt.title(f'Distribution of {col}')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('Count')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "else:\n",
    "    print('\\nNo categorical features found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fc20e7",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec02e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*60)\n",
    "print('EXPLORATORY DATA ANALYSIS SUMMARY')\n",
    "print('='*60)\n",
    "print(f'\\nðŸ“Š Dataset Shape: {df.shape}')\n",
    "print(f'ðŸ”¢ Numerical Features: {len(numerical_cols)}')\n",
    "print(f'ðŸ“ Categorical Features: {len(categorical_cols)}')\n",
    "print(f'âŒ Missing Values: {df.isnull().sum().sum()}')\n",
    "print(f'ðŸ”„ Duplicate Rows: {df.duplicated().sum()}')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('NEXT STEPS')\n",
    "print('='*60)\n",
    "print('1. Handle missing values (if any)')\n",
    "print('2. Address outliers (if necessary)')\n",
    "print('3. Feature engineering and selection')\n",
    "print('4. Encode categorical variables')\n",
    "print('5. Scale/normalize features')\n",
    "print('6. Split data into train/test sets')\n",
    "print('7. Build and evaluate models')\n",
    "print('\\nâœ“ EDA Complete!')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
