{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "937eab1c",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "## Masters in AI & ML Project\n",
    "\n",
    "This notebook focuses on feature creation, selection, and transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08825b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('âœ“ Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff24cc19",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995c8a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "data_path = '../data/raw/your_dataset.csv'\n",
    "\n",
    "# For demonstration\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=15, n_informative=10,\n",
    "                          n_redundant=3, n_repeated=2, random_state=42)\n",
    "df = pd.DataFrame(X, columns=[f'Feature_{i+1}' for i in range(15)])\n",
    "df['Target'] = y\n",
    "\n",
    "print(f'Dataset loaded: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2635340c",
   "metadata": {},
   "source": [
    "## 2. Create New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfbb93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Examples\n",
    "# Customize based on your domain and data\n",
    "\n",
    "# Example 1: Interaction features\n",
    "df['Feature_1x2'] = df['Feature_1'] * df['Feature_2']\n",
    "\n",
    "# Example 2: Polynomial features\n",
    "df['Feature_1_squared'] = df['Feature_1'] ** 2\n",
    "\n",
    "# Example 3: Ratio features\n",
    "df['Feature_1_2_ratio'] = df['Feature_1'] / (df['Feature_2'] + 1e-6)\n",
    "\n",
    "# Example 4: Binning continuous features\n",
    "df['Feature_1_binned'] = pd.cut(df['Feature_1'], bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "print(f'\\nâœ“ New features created. Dataset shape: {df.shape}')\n",
    "print(f'\\nNew columns: {[col for col in df.columns if \"x\" in col or \"squared\" in col or \"ratio\" in col or \"binned\" in col]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f4e9b",
   "metadata": {},
   "source": [
    "## 3. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e18c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for feature selection\n",
    "target_col = 'Target'\n",
    "X = df.select_dtypes(include=[np.number]).drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "print(f'Features for selection: {X.shape[1]}')\n",
    "print(f'Target distribution: {y.value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069cfa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Statistical Test (ANOVA F-value)\n",
    "selector = SelectKBest(score_func=f_classif, k=10)\n",
    "selector.fit(X, y)\n",
    "\n",
    "# Get feature scores\n",
    "feature_scores = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'F-Score': selector.scores_\n",
    "}).sort_values('F-Score', ascending=False)\n",
    "\n",
    "print('\\nðŸ“Š Top 10 Features by F-Score:')\n",
    "print(feature_scores.head(10))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_scores['Feature'].head(10), feature_scores['F-Score'].head(10))\n",
    "plt.xlabel('F-Score')\n",
    "plt.title('Top 10 Features by ANOVA F-Score')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7915032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Mutual Information\n",
    "mi_scores = mutual_info_classif(X, y, random_state=42)\n",
    "\n",
    "mi_feature_scores = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'MI-Score': mi_scores\n",
    "}).sort_values('MI-Score', ascending=False)\n",
    "\n",
    "print('\\nðŸ“Š Top 10 Features by Mutual Information:')\n",
    "print(mi_feature_scores.head(10))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(mi_feature_scores['Feature'].head(10), mi_feature_scores['MI-Score'].head(10))\n",
    "plt.xlabel('Mutual Information Score')\n",
    "plt.title('Top 10 Features by Mutual Information')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deff986",
   "metadata": {},
   "source": [
    "## 4. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec943ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler (zero mean, unit variance)\n",
    "scaler_standard = StandardScaler()\n",
    "X_scaled_standard = scaler_standard.fit_transform(X)\n",
    "\n",
    "# MinMaxScaler (0-1 range)\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_scaled_minmax = scaler_minmax.fit_transform(X)\n",
    "\n",
    "# Compare scaling methods\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Original\n",
    "axes[0].boxplot(X.iloc[:, :5].values)\n",
    "axes[0].set_title('Original Features')\n",
    "axes[0].set_xticklabels(X.columns[:5], rotation=45)\n",
    "\n",
    "# StandardScaler\n",
    "axes[1].boxplot(X_scaled_standard[:, :5])\n",
    "axes[1].set_title('StandardScaler')\n",
    "axes[1].set_xticklabels(X.columns[:5], rotation=45)\n",
    "\n",
    "# MinMaxScaler\n",
    "axes[2].boxplot(X_scaled_minmax[:, :5])\n",
    "axes[2].set_title('MinMaxScaler')\n",
    "axes[2].set_xticklabels(X.columns[:5], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nâœ“ Feature scaling completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfd0ca4",
   "metadata": {},
   "source": [
    "## 5. Dimensionality Reduction (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f4244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled_standard)\n",
    "\n",
    "# Explained variance\n",
    "explained_var = pca.explained_variance_ratio_\n",
    "cumulative_var = np.cumsum(explained_var)\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scree plot\n",
    "ax1.plot(range(1, len(explained_var) + 1), explained_var, 'bo-')\n",
    "ax1.set_xlabel('Principal Component')\n",
    "ax1.set_ylabel('Explained Variance Ratio')\n",
    "ax1.set_title('Scree Plot')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Cumulative variance\n",
    "ax2.plot(range(1, len(cumulative_var) + 1), cumulative_var, 'ro-')\n",
    "ax2.axhline(y=0.95, color='g', linestyle='--', label='95% Variance')\n",
    "ax2.set_xlabel('Number of Components')\n",
    "ax2.set_ylabel('Cumulative Explained Variance')\n",
    "ax2.set_title('Cumulative Explained Variance')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find number of components for 95% variance\n",
    "n_components_95 = np.argmax(cumulative_var >= 0.95) + 1\n",
    "print(f'\\nðŸ“Š Components needed for 95% variance: {n_components_95} out of {len(explained_var)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b99c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first two principal components\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', alpha=0.6)\n",
    "plt.xlabel(f'PC1 ({explained_var[0]:.2%} variance)')\n",
    "plt.ylabel(f'PC2 ({explained_var[1]:.2%} variance)')\n",
    "plt.title('First Two Principal Components')\n",
    "plt.colorbar(scatter, label='Target')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db667faf",
   "metadata": {},
   "source": [
    "## 6. Save Processed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8957852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final feature set\n",
    "# Select top features based on your analysis\n",
    "top_features = feature_scores['Feature'].head(10).tolist()\n",
    "\n",
    "df_final = df[top_features + [target_col]].copy()\n",
    "\n",
    "print(f'\\nâœ“ Final dataset shape: {df_final.shape}')\n",
    "print(f'\\nSelected features: {top_features}')\n",
    "\n",
    "# Save to processed directory\n",
    "output_path = '../data/processed/processed_features.csv'\n",
    "df_final.to_csv(output_path, index=False)\n",
    "print(f'\\nâœ“ Processed features saved to: {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c71bb2d",
   "metadata": {},
   "source": [
    "## 7. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d06a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*60)\n",
    "print('FEATURE ENGINEERING SUMMARY')\n",
    "print('='*60)\n",
    "print(f'\\nðŸ“Š Original Features: {X.shape[1]}')\n",
    "print(f'ðŸŽ¯ Selected Features: {len(top_features)}')\n",
    "print(f'ðŸ“‰ Dimensionality Reduction: {n_components_95} components for 95% variance')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('NEXT STEPS')\n",
    "print('='*60)\n",
    "print('1. Use processed features for model training')\n",
    "print('2. Experiment with different feature combinations')\n",
    "print('3. Consider domain-specific feature engineering')\n",
    "print('4. Test model performance with selected features')\n",
    "print('\\nâœ“ Feature Engineering Complete!')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
